"""
RQ Worker å•Ÿå‹•è…³æœ¬

å•Ÿå‹• RQ Worker ä¾†è™•ç†åœ–ç‰‡ä¸Šå‚³ä»»å‹™ã€‚

ç”¨æ³•:
    # é–‹ç™¼ç’°å¢ƒ
    python -m src.namecard.infrastructure.storage.rq_worker

    # æˆ–ç›´æ¥é‹è¡Œ
    python src/namecard/infrastructure/storage/rq_worker.py

    # ç”Ÿç”¢ç’°å¢ƒï¼ˆä½¿ç”¨ rq å‘½ä»¤ï¼‰
    rq worker image_upload --url redis://localhost:6379/0
"""

import sys
import os
import socket
import time
import json
import uuid

# ç¢ºä¿å°ˆæ¡ˆæ ¹ç›®éŒ„åœ¨ Python path ä¸­
project_root = os.path.dirname(
    os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))
)
if project_root not in sys.path:
    sys.path.insert(0, project_root)

import structlog
from simple_config import settings

logger = structlog.get_logger()

# #region agent log
DEBUG_LOG_PATH = "/Users/user/Ecofirst_namecard/.cursor/debug.log"

def _is_debug_log_enabled():
    """
    æª¢æŸ¥èª¿è©¦æ—¥èªŒæ˜¯å¦å•Ÿç”¨
    
    é€šéç’°å¢ƒè®Šæ•¸ RQ_WORKER_DEBUG_LOG æ§åˆ¶ï¼š
    - æœªè¨­ç½®æˆ–è¨­ç½®ç‚º "true"/"1"/"yes" -> å•Ÿç”¨ï¼ˆé»˜èªï¼‰
    - è¨­ç½®ç‚º "false"/"0"/"no" -> ç¦ç”¨
    
    Returns:
        bool: True è¡¨ç¤ºå•Ÿç”¨èª¿è©¦æ—¥èªŒï¼ŒFalse è¡¨ç¤ºç¦ç”¨
    """
    debug_env = os.getenv("RQ_WORKER_DEBUG_LOG", "true").lower()
    return debug_env in ("true", "1", "yes", "")


def _debug_log(hypothesis_id, location, message, data=None):
    """
    èª¿è©¦æ—¥èªŒå‡½æ•¸
    
    å¯é€šéç’°å¢ƒè®Šæ•¸ RQ_WORKER_DEBUG_LOG æ§åˆ¶æ˜¯å¦å•Ÿç”¨ï¼š
    - é»˜èªå•Ÿç”¨ï¼ˆæœ‰åŠ©æ–¼ç”Ÿç”¢ç’°å¢ƒå•é¡Œæ’æŸ¥ï¼‰
    - è¨­ç½® RQ_WORKER_DEBUG_LOG=false å¯ç¦ç”¨
    
    Args:
        hypothesis_id: å‡è¨­ IDï¼ˆç”¨æ–¼èª¿è©¦è¿½è¹¤ï¼‰
        location: ä»£ç¢¼ä½ç½®
        message: æ—¥èªŒè¨Šæ¯
        data: é™„åŠ æ•¸æ“šï¼ˆå¯é¸ï¼‰
    """
    # æª¢æŸ¥æ˜¯å¦å•Ÿç”¨èª¿è©¦æ—¥èªŒ
    if not _is_debug_log_enabled():
        return
    
    log_entry = {
        "sessionId": "debug-session",
        "runId": "post-fix-v2",
        "hypothesisId": hypothesis_id,
        "location": location,
        "message": message,
        "data": data or {},
        "timestamp": int(time.time() * 1000)
    }
    # åŒæ™‚å¯«å…¥æª”æ¡ˆå’Œ stdoutï¼ˆå®¹å™¨ç’°å¢ƒå¯èƒ½ç„¡æ³•å¯«å…¥æª”æ¡ˆï¼‰
    try:
        with open(DEBUG_LOG_PATH, "a") as f:
            f.write(json.dumps(log_entry) + "\n")
    except Exception:
        pass
    # ä¹Ÿè¼¸å‡ºåˆ° stdout ä»¥ä¾¿åœ¨å®¹å™¨æ—¥èªŒä¸­çœ‹åˆ°
    try:
        print(f"[DEBUG] {location}: {message} | {json.dumps(data or {})}", flush=True)
    except Exception:
        pass
# #endregion


def create_rq_redis_client():
    """
    å‰µå»ºå°ˆç”¨æ–¼ RQ çš„ Redis å®¢æˆ¶ç«¯
    
    RQ éœ€è¦ decode_responses=False ä¾†æ­£ç¢ºè™•ç†åºåˆ—åŒ–çš„ä»»å‹™è³‡æ–™
    RQ Worker éœ€è¦é•·æœŸé€£æ¥ï¼Œæ‰€ä»¥ä½¿ç”¨è¼ƒé•·çš„è¶…æ™‚å’Œ keepalive
    """
    import redis
    
    # RQ Worker éœ€è¦è¼ƒé•·çš„è¶…æ™‚ï¼ˆç”¨æ–¼ PubSub ç›£è½ï¼‰
    # è¨­ç½® None è¡¨ç¤ºç„¡è¶…æ™‚ï¼Œè®“ Worker å¯ä»¥ä¸€ç›´ç­‰å¾…ä»»å‹™
    rq_socket_timeout = None  # ç„¡è¶…æ™‚ï¼ŒWorker æœƒä¸€ç›´ç­‰å¾…
    
    # å„ªå…ˆä½¿ç”¨ REDIS_URL
    if settings.redis_url:
        logger.info("ğŸ”— [RQ] Connecting to Redis using REDIS_URL")
        return redis.from_url(
            settings.redis_url,
            decode_responses=False,  # RQ éœ€è¦ False
            socket_timeout=rq_socket_timeout,
            socket_keepalive=True,  # ä¿æŒ TCP é€£æ¥æ´»èº
            health_check_interval=30,  # æ¯ 30 ç§’æª¢æŸ¥é€£æ¥å¥åº·
        )
    else:
        logger.info(
            "ğŸ”— [RQ] Connecting to Redis using host/port configuration",
            host=settings.redis_host,
            port=settings.redis_port,
            db=settings.redis_db,
        )
        return redis.Redis(
            host=settings.redis_host,
            port=settings.redis_port,
            password=settings.redis_password,
            db=settings.redis_db,
            decode_responses=False,  # RQ éœ€è¦ False
            socket_timeout=rq_socket_timeout,
            socket_keepalive=True,  # ä¿æŒ TCP é€£æ¥æ´»èº
            health_check_interval=30,  # æ¯ 30 ç§’æª¢æŸ¥é€£æ¥å¥åº·
        )


def is_worker_expired(worker, timeout_seconds=60):
    """
    æª¢æŸ¥ worker æ˜¯å¦éæœŸ
    
    Args:
        worker: RQ Worker å¯¦ä¾‹
        timeout_seconds: è¶…æ™‚æ™‚é–“ï¼ˆç§’ï¼‰ï¼Œé»˜èª 60 ç§’
    
    Returns:
        bool: True è¡¨ç¤º worker å·²éæœŸï¼ŒFalse è¡¨ç¤º worker ä»æ´»èºæˆ–ç„¡æ³•ç¢ºå®š
    """
    try:
        # æª¢æŸ¥æœ€å¾Œå¿ƒè·³æ™‚é–“
        if hasattr(worker, 'last_heartbeat') and worker.last_heartbeat:
            time_since_heartbeat = time.time() - worker.last_heartbeat
            is_expired = time_since_heartbeat > timeout_seconds
            logger.debug(
                "Checked worker heartbeat",
                worker_name=worker.name,
                time_since_heartbeat=time_since_heartbeat,
                is_expired=is_expired
            )
            return is_expired
        
        # å¦‚æœç„¡æ³•ç²å–å¿ƒè·³æ™‚é–“ï¼Œæª¢æŸ¥ worker ç‹€æ…‹
        if hasattr(worker, 'get_state'):
            try:
                state = worker.get_state()
                # å¦‚æœç‹€æ…‹ä¸æ˜¯æ´»èºç‹€æ…‹ï¼Œå¯èƒ½æ˜¯éæœŸçš„
                is_expired = state not in ('started', 'busy', 'idle')
                logger.debug(
                    "Checked worker state",
                    worker_name=worker.name,
                    state=state,
                    is_expired=is_expired
                )
                return is_expired
            except Exception:
                pass
        
        # ä¿å®ˆè™•ç†ï¼šç„¡æ³•ç¢ºå®šæ™‚è¿”å› Falseï¼ˆä¸æ¸…ç†ï¼‰
        logger.debug(
            "Cannot determine worker expiration status, treating as active",
            worker_name=worker.name
        )
        return False
    except Exception as e:
        # å‡ºéŒ¯æ™‚ä¿å®ˆè™•ç†
        logger.warning(
            "Error checking worker expiration",
            worker_name=getattr(worker, 'name', 'unknown'),
            error=str(e)
        )
        return False


def cleanup_worker_from_redis(redis_client, worker_name):
    """
    ç›´æ¥å¾ Redis æ¸…ç† worker è¨»å†Š
    
    Args:
        redis_client: Redis å®¢æˆ¶ç«¯å¯¦ä¾‹
        worker_name: Worker åç¨±
    
    Returns:
        int: åˆªé™¤çš„ key æ•¸é‡
    """
    try:
        # RQ å­˜å„² worker è³‡è¨Šçš„ä¸»è¦ key
        worker_key = f"rq:worker:{worker_name}".encode('utf-8')
        deleted = redis_client.delete(worker_key)
        
        # åˆªé™¤æ‰€æœ‰ç›¸é—œ keysï¼ˆä½¿ç”¨æ¨¡å¼åŒ¹é…ï¼‰
        pattern = f"rq:worker:{worker_name}*".encode('utf-8')
        keys_to_delete = list(redis_client.scan_iter(match=pattern))
        if keys_to_delete:
            deleted += redis_client.delete(*keys_to_delete)
        
        # ä¹Ÿå¾ RQ çš„ workers é›†åˆä¸­ç§»é™¤ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        try:
            redis_client.srem("rq:workers".encode('utf-8'), worker_name.encode('utf-8'))
        except Exception:
            pass  # é›†åˆå¯èƒ½ä¸å­˜åœ¨ï¼Œå¿½ç•¥éŒ¯èª¤
        
        return deleted
    except Exception as e:
        logger.warning("Error in cleanup_worker_from_redis", worker_name=worker_name, error=str(e))
        return 0


def cleanup_stale_workers(redis_client, proposed_worker_name, logger_instance=None):
    """
    æ¸…ç†éæœŸçš„ worker è¨»å†Š
    
    ç­–ç•¥ï¼š
    1. åªæ¸…ç†èˆŠæ ¼å¼çš„ workerï¼ˆimage-upload-worker-{pid}ï¼‰
    2. æª¢æŸ¥ worker æ˜¯å¦çœŸçš„éæœŸï¼ˆæœ€å¾Œå¿ƒè·³ > 60ç§’ï¼‰
    3. ä¸æ¸…ç†æ–°æ ¼å¼çš„ workerï¼ˆåŒ…å« UUIDï¼‰
    4. æ¸…ç†èˆ‡æ–°åç¨±å®Œå…¨ç›¸åŒçš„ workerï¼ˆæ¥µä¸å¯èƒ½ä½†ä»¥é˜²è¬ä¸€ï¼‰
    
    Args:
        redis_client: Redis å®¢æˆ¶ç«¯å¯¦ä¾‹
        proposed_worker_name: æè­°çš„æ–° worker åç¨±
        logger_instance: æ—¥èªŒå¯¦ä¾‹ï¼ˆå¯é¸ï¼Œé»˜èªä½¿ç”¨æ¨¡çµ„ç´š loggerï¼‰
    
    Returns:
        tuple: (cleaned_count, cleaned_names) - æ¸…ç†çš„æ•¸é‡å’Œåç¨±åˆ—è¡¨
    """
    if logger_instance is None:
        logger_instance = logger
    
    from rq import Worker
    
    cleaned_count = 0
    cleaned_names = []
    
    try:
        # æ–¹æ³•1: é€šé RQ Worker.all() ç²å–ä¸¦æ¸…ç†
        existing_workers = Worker.all(connection=redis_client)
        worker_names_before = [w.name for w in existing_workers]
        
        logger_instance.info(
            "Checking existing workers for cleanup",
            count=len(existing_workers),
            names=worker_names_before
        )
        
        for worker in existing_workers:
            try:
                worker_name = worker.name
                should_clean = False
                reason = ""
                
                # æƒ…æ³1: èˆ‡æ–°åç¨±å®Œå…¨ç›¸åŒï¼ˆæ¥µä¸å¯èƒ½ä½†ä»¥é˜²è¬ä¸€ï¼‰
                if worker_name == proposed_worker_name:
                    should_clean = True
                    reason = "exact_name_match"
                    logger_instance.warning(
                        "Found duplicate worker name",
                        worker_name=worker_name,
                        reason=reason
                    )
                # æƒ…æ³2: èˆŠæ ¼å¼çš„ workerï¼ˆimage-upload-worker-{pid}ï¼‰
                elif worker_name.startswith("image-upload-worker-") and worker_name.count("-") == 2:
                    parts = worker_name.split("-")
                    if len(parts) == 4 and parts[-1].isdigit():  # æœ€å¾Œä¸€éƒ¨åˆ†æ˜¯ç´”æ•¸å­—ï¼ˆPIDï¼‰
                        # æª¢æŸ¥ worker æ˜¯å¦éæœŸ
                        if is_worker_expired(worker, timeout_seconds=60):
                            should_clean = True
                            reason = "old_format_expired"
                            logger_instance.info(
                                "Found expired old-format worker",
                                worker_name=worker_name,
                                reason=reason
                            )
                        else:
                            logger_instance.debug(
                                "Old-format worker is still active, skipping",
                                worker_name=worker_name
                            )
                
                if should_clean:
                    logger_instance.warning(
                        "Cleaning up worker",
                        worker_name=worker_name,
                        reason=reason
                    )
                    try:
                        # æ–¹æ³•1: å˜—è©¦ä½¿ç”¨ RQ çš„ register_death()
                        try:
                            worker.register_death()
                            logger_instance.debug("Registered worker death via RQ API", worker_name=worker_name)
                        except Exception as e:
                            logger_instance.debug(
                                "Failed to register_death via RQ API, using direct Redis cleanup",
                                worker_name=worker_name,
                                error=str(e)
                            )
                        
                        # æ–¹æ³•2: ç›´æ¥åˆªé™¤ Redis keysï¼ˆæ›´å¾¹åº•ï¼‰
                        deleted = cleanup_worker_from_redis(redis_client, worker_name)
                        
                        if deleted > 0:
                            cleaned_count += 1
                            cleaned_names.append(worker_name)
                            logger_instance.info(
                                "Successfully cleaned up worker from Redis",
                                worker_name=worker_name,
                                deleted_keys=deleted,
                                reason=reason
                            )
                        else:
                            logger_instance.warning(
                                "No keys deleted for worker",
                                worker_name=worker_name
                            )
                    except Exception as cleanup_error:
                        logger_instance.warning(
                            "Failed to cleanup worker from Redis",
                            worker_name=worker_name,
                            error=str(cleanup_error)
                        )
            except Exception as e:
                logger_instance.warning(
                    "Failed to check/clean worker",
                    worker_name=getattr(worker, 'name', 'unknown'),
                    error=str(e)
                )
        
        # æ–¹æ³•2: ç›´æ¥æƒæ Redis æŸ¥æ‰¾æ‰€æœ‰èˆŠæ ¼å¼çš„ worker keys ä¸¦æ¸…ç†
        # é€™ç¢ºä¿å³ä½¿ Worker.all() æ²’æœ‰è¿”å›æŸäº› workerï¼Œæˆ‘å€‘ä¹Ÿèƒ½æ¸…ç†å®ƒå€‘
        try:
            pattern = "rq:worker:image-upload-worker-*".encode('utf-8')
            all_worker_keys = list(redis_client.scan_iter(match=pattern))
            
            for key in all_worker_keys:
                try:
                    # å¾ key ä¸­æå– worker åç¨±
                    key_str = key.decode('utf-8') if isinstance(key, bytes) else key
                    if key_str.startswith("rq:worker:image-upload-worker-"):
                        worker_name_from_key = key_str.replace("rq:worker:", "")
                        
                        # åªè™•ç†èˆŠæ ¼å¼çš„ workerï¼ˆå·²ç¶“åœ¨ cleaned_names ä¸­çš„è·³éï¼‰
                        if worker_name_from_key not in cleaned_names:
                            # æª¢æŸ¥æ˜¯å¦ç‚ºèˆŠæ ¼å¼
                            if worker_name_from_key.count("-") == 2:
                                parts = worker_name_from_key.split("-")
                                if len(parts) == 4 and parts[-1].isdigit():
                                    logger_instance.warning(
                                        "Found additional old-format worker key in Redis, cleaning up",
                                        worker_name=worker_name_from_key,
                                        key=key_str
                                    )
                                    deleted = cleanup_worker_from_redis(redis_client, worker_name_from_key)
                                    if deleted > 0:
                                        cleaned_count += 1
                                        cleaned_names.append(worker_name_from_key)
                except Exception as e:
                    logger_instance.warning("Error processing worker key", key=key, error=str(e))
        except Exception as scan_error:
            logger_instance.warning("Failed to scan Redis for worker keys", error=str(scan_error))
        
        if cleaned_count > 0:
            logger_instance.info(
                "Cleaned up stale worker registrations",
                count=cleaned_count,
                names=cleaned_names
            )
        else:
            logger_instance.info("No stale workers found to clean")
        
        return cleaned_count, cleaned_names
        
    except Exception as e:
        logger_instance.warning(
            "Failed to check/clean existing workers",
            error=str(e),
            error_type=type(e).__name__
        )
        return 0, []


def start_worker():
    """å•Ÿå‹• RQ Worker"""
    try:
        from rq import Worker, Queue
        from src.namecard.infrastructure.storage.image_upload_worker import RQ_QUEUE_NAME
    except ImportError as e:
        logger.error("Required packages not installed", error=str(e))
        logger.info("Please install: pip install rq redis")
        sys.exit(1)

    # å‰µå»º RQ å°ˆç”¨çš„ Redis é€£æ¥ï¼ˆdecode_responses=Falseï¼‰
    try:
        redis_client = create_rq_redis_client()
        redis_client.ping()
        logger.info("âœ… [RQ] Redis connection established successfully")
    except Exception as e:
        logger.error("Failed to connect to Redis", error=str(e))
        logger.info("Please ensure Redis is running and REDIS_URL is configured")
        sys.exit(1)

    logger.info("Starting RQ Worker", queue=RQ_QUEUE_NAME, redis_enabled=settings.redis_enabled)

    # #region agent log
    current_pid = os.getpid()
    hostname = socket.gethostname()
    _debug_log("A", "rq_worker.py:118", "Worker startup - PID and hostname", {
        "pid": current_pid,
        "hostname": hostname,
        "queue_name": RQ_QUEUE_NAME
    })
    # #endregion

    # å‰µå»ºéšŠåˆ—
    queue = Queue(RQ_QUEUE_NAME, connection=redis_client)

    # ç”Ÿæˆå”¯ä¸€çš„ worker åç¨±ï¼šåŒ…å« hostnameã€PID å’Œ UUID å‰ç¶´
    # é€™æ¨£å³ä½¿åŒä¸€å®¹å™¨é‡å•Ÿä¸” PID ç›¸åŒï¼ŒUUID ä¹Ÿæœƒä¸åŒ
    unique_id = str(uuid.uuid4())[:8]  # ä½¿ç”¨ UUID å‰ 8 å€‹å­—ç¬¦ä½œç‚ºå”¯ä¸€æ¨™è­˜
    # æ¸…ç† hostname ä¸­çš„ç‰¹æ®Šå­—ç¬¦ï¼ˆç”¨æ–¼ worker åç¨±ï¼‰
    safe_hostname = hostname.replace('.', '-').replace('_', '-')[:20]  # é™åˆ¶é•·åº¦
    proposed_worker_name = f"image-upload-worker-{safe_hostname}-{current_pid}-{unique_id}"
    
    # #region agent log
    _debug_log("A", "rq_worker.py:151", "Generated unique worker name", {
        "proposed_name": proposed_worker_name,
        "pid": current_pid,
        "hostname": hostname,
        "unique_id": unique_id
    })
    # #endregion

    # æ¸…ç†å¯èƒ½è¡çªçš„ worker è¨»å†Šï¼ˆé˜²æ­¢é‡å•Ÿæ™‚çš„è¡çªï¼‰
    # ä½¿ç”¨ä¿å®ˆçš„æ¸…ç†ç­–ç•¥ï¼šåªæ¸…ç†çœŸæ­£éæœŸçš„èˆŠæ ¼å¼ worker
    # #region agent log
    _debug_log("B", "rq_worker.py:start_cleanup", "Starting worker cleanup", {
        "proposed_worker_name": proposed_worker_name
    })
    # #endregion
    
    cleaned_count, cleaned_names = cleanup_stale_workers(redis_client, proposed_worker_name, logger)
    
    if cleaned_count > 0:
        _debug_log("B", "rq_worker.py:after_cleanup", "Cleaned up stale workers", {
            "cleaned_count": cleaned_count,
            "cleaned_names": cleaned_names
        })
        # ç­‰å¾…ä¸€å°æ®µæ™‚é–“ç¢ºä¿ Redis æ›´æ–°
        time.sleep(0.5)
    else:
        _debug_log("B", "rq_worker.py:after_cleanup", "No stale workers to clean", {})
    # #endregion
    
    # å‰µå»ºä¸¦å•Ÿå‹• Worker
    # #region agent log
    _debug_log("C", "rq_worker.py:202", "Creating Worker instance", {
        "worker_name": proposed_worker_name,
        "queue_name": RQ_QUEUE_NAME
    })
    # #endregion
    
    try:
        worker = Worker([queue], connection=redis_client, name=proposed_worker_name)
        # #region agent log
        _debug_log("C", "rq_worker.py:208", "Worker instance created successfully", {
            "worker_name": worker.name,
            "worker_id": getattr(worker, 'id', None)
        })
        # #endregion
    except ValueError as e:
        # #region agent log
        _debug_log("A", "rq_worker.py:214", "Worker creation failed - duplicate name", {
            "error": str(e),
            "proposed_name": proposed_worker_name,
            "pid": current_pid,
            "hostname": hostname,
            "unique_id": unique_id
        })
        # #endregion
        raise

    logger.info("RQ Worker started, waiting for jobs...", worker_name=worker.name)

    # #region agent log
    _debug_log("D", "rq_worker.py:223", "About to call worker.work()", {
        "worker_name": worker.name
    })
    # #endregion

    # é–‹å§‹è™•ç†ä»»å‹™
    # ä½¿ç”¨ try-except æ•ç² register_birth æ™‚çš„éŒ¯èª¤
    try:
        worker.work(with_scheduler=False)
    except ValueError as e:
        error_msg = str(e)
        # #region agent log
        _debug_log("D", "rq_worker.py:232", "worker.work() failed - duplicate worker", {
            "error": error_msg,
            "worker_name": worker.name
        })
        # #endregion
        
        # å¦‚æœæ˜¯é‡è¤‡ worker çš„éŒ¯èª¤ï¼Œå˜—è©¦æ¸…ç†å¾Œé‡è©¦ä¸€æ¬¡
        if "There exists an active worker named" in error_msg:
            logger.warning(
                "Duplicate worker detected during registration, attempting cleanup and retry",
                worker_name=worker.name,
                error=error_msg
            )
            
            # #region agent log
            _debug_log("D", "rq_worker.py:245", "Duplicate worker error detected", {
                "error": error_msg,
                "worker_name": worker.name
            })
            # #endregion
            
            # æå–éŒ¯èª¤è¨Šæ¯ä¸­çš„ worker åç¨±
            conflicting_name = None
            if "named '" in error_msg and "' already" in error_msg:
                try:
                    start = error_msg.index("named '") + 7
                    end = error_msg.index("' already", start)
                    conflicting_name = error_msg[start:end]
                    logger.info("Extracted conflicting worker name from error", conflicting_name=conflicting_name)
                except (ValueError, IndexError):
                    pass
            
            # å†æ¬¡å˜—è©¦æ¸…ç†ï¼šå…ˆæ¸…ç†è¡çªçš„ workerï¼Œç„¶å¾Œæ¸…ç†æ‰€æœ‰éæœŸ worker
            try:
                # å¦‚æœæœ‰è¡çªçš„ worker åç¨±ï¼Œå…ˆé‡å°æ€§æ¸…ç†å®ƒ
                if conflicting_name:
                    logger.warning(
                        "Cleaning up conflicting worker specifically",
                        conflicting_name=conflicting_name
                    )
                    try:
                        # ç›´æ¥æ¸…ç†è¡çªçš„ worker
                        deleted = cleanup_worker_from_redis(redis_client, conflicting_name)
                        if deleted > 0:
                            logger.info(
                                "Successfully cleaned up conflicting worker",
                                worker_name=conflicting_name,
                                deleted_keys=deleted
                            )
                        # ä¹Ÿå˜—è©¦ä½¿ç”¨ RQ API
                        try:
                            from rq import Worker
                            all_workers = Worker.all(connection=redis_client)
                            for w in all_workers:
                                if w.name == conflicting_name:
                                    try:
                                        w.register_death()
                                        logger.debug("Registered conflicting worker death via RQ API", worker_name=conflicting_name)
                                    except Exception:
                                        pass
                        except Exception:
                            pass
                    except Exception as cleanup_err:
                        logger.warning(
                            "Failed to cleanup conflicting worker",
                            worker_name=conflicting_name,
                            error=str(cleanup_err)
                        )
                
                # ç„¶å¾Œæ¸…ç†æ‰€æœ‰éæœŸçš„èˆŠæ ¼å¼ workerï¼ˆé‡ç”¨æ¸…ç†å‡½æ•¸ï¼‰
                # ä½¿ç”¨ç•¶å‰ worker åç¨±ä½œç‚ºåƒè€ƒï¼ˆç¨å¾Œæœƒç”Ÿæˆæ–°çš„å”¯ä¸€åç¨±ï¼‰
                cleaned_count_retry, cleaned_names_retry = cleanup_stale_workers(
                    redis_client,
                    worker.name,  # ä½¿ç”¨ç•¶å‰ worker åç¨±
                    logger
                )
                
                if cleaned_count_retry > 0:
                    logger.info(
                        "Cleaned up workers during retry",
                        count=cleaned_count_retry,
                        names=cleaned_names_retry
                    )
                    # #region agent log
                    _debug_log("D", "rq_worker.py:retry_cleanup", "Cleaned up workers during retry", {
                        "cleaned_count": cleaned_count_retry,
                        "cleaned_names": cleaned_names_retry,
                        "conflicting_name": conflicting_name
                    })
                    # #endregion
            except Exception as cleanup_error:
                logger.warning("Failed to cleanup during retry", error=str(cleanup_error))
                # #region agent log
                _debug_log("D", "rq_worker.py:retry_cleanup_failed", "Failed to cleanup during retry", {
                    "error": str(cleanup_error)
                })
                # #endregion
            
            # ç­‰å¾…ä¸€å°æ®µæ™‚é–“è®“ Redis æ›´æ–°
            time.sleep(1.0)  # ç¢ºä¿ Redis æ›´æ–°å®Œæˆ
            
            # ä½¿ç”¨æ–°çš„å”¯ä¸€åç¨±é‡è©¦
            retry_unique_id = str(uuid.uuid4())[:8]
            retry_worker_name = f"image-upload-worker-{safe_hostname}-{current_pid}-{retry_unique_id}"
            logger.info("Retrying with new worker name", new_name=retry_worker_name, original_name=worker.name)
            
            # #region agent log
            _debug_log("D", "rq_worker.py:304", "Retrying with new worker name", {
                "original_name": worker.name,
                "retry_name": retry_worker_name,
                "conflicting_name": conflicting_name
            })
            # #endregion
            
            # å‰µå»ºæ–°çš„ worker ä¸¦é‡è©¦
            try:
                retry_worker = Worker([queue], connection=redis_client, name=retry_worker_name)
                logger.info("Retry worker created, starting work...", worker_name=retry_worker_name)
                retry_worker.work(with_scheduler=False)
            except ValueError as retry_error:
                # å¦‚æœé‡è©¦ä»ç„¶å¤±æ•—ï¼Œè¨˜éŒ„è©³ç´°è³‡è¨Šä¸¦æ‹‹å‡º
                logger.error(
                    "Retry failed with new unique name - this should not happen",
                    retry_worker_name=retry_worker_name,
                    error=str(retry_error)
                )
                # #region agent log
                _debug_log("D", "rq_worker.py:320", "Retry failed - unexpected", {
                    "retry_worker_name": retry_worker_name,
                    "error": str(retry_error)
                })
                # #endregion
                raise
        else:
            # å…¶ä»–éŒ¯èª¤ç›´æ¥æ‹‹å‡º
            raise


if __name__ == "__main__":
    start_worker()
