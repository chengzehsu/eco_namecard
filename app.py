#!/usr/bin/env python3
"""
LINE Bot åç‰‡ç®¡ç†ç³»çµ± - ä¸»å•Ÿå‹•æ–‡ä»¶ï¼ˆå¤šç§Ÿæˆ¶ç‰ˆï¼‰
æ™ºèƒ½ LINE Bot åç‰‡ç®¡ç†ç³»çµ±ï¼Œä½¿ç”¨ Google Gemini AI è­˜åˆ¥åç‰‡å…§å®¹ï¼Œä¸¦è‡ªå‹•å­˜å…¥ Notion è³‡æ–™åº«

æ”¯æ´å¤šç§Ÿæˆ¶æ¨¡å¼ï¼š
- ç®¡ç†å¾Œå° (/admin) ç”¨æ–¼ç®¡ç†å¤šå€‹ LINE Bot ç§Ÿæˆ¶
- æ¯å€‹ç§Ÿæˆ¶å¯æœ‰ç¨ç«‹çš„ LINE Bot å’Œ Notion Database
"""

import os
import sys
import structlog
import json
from datetime import datetime

# æ·»åŠ é …ç›®æ ¹ç›®éŒ„åˆ° Python è·¯å¾‘
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# #region agent log
import os as _os_for_debug
_DEBUG_LOG_PATH = _os_for_debug.path.join(_os_for_debug.path.dirname(_os_for_debug.path.abspath(__file__)), ".cursor", "debug.log")
_os_for_debug.makedirs(_os_for_debug.path.dirname(_DEBUG_LOG_PATH), exist_ok=True)
def _debug_log(hypothesis_id: str, location: str, message: str, data: dict = None):
    try:
        import json, time
        log_entry = {"hypothesisId": hypothesis_id, "location": location, "message": message, "data": data or {}, "timestamp": int(time.time() * 1000), "sessionId": "debug-session"}
        with open(_DEBUG_LOG_PATH, "a") as f:
            f.write(json.dumps(log_entry) + "\n")
    except Exception as e:
        # å¦‚æœç„¡æ³•å¯«å…¥æ–‡ä»¶ï¼Œè‡³å°‘æ‰“å°åˆ° stdoutï¼ˆZeabur æœƒæ•ç²ï¼‰
        print(f"DEBUG_LOG: {json.dumps(log_entry) if 'log_entry' in dir() else message}")

_debug_log("A", "app.py:1", "APP_STARTUP_BEGIN", {"step": "imports", "debug_log_path": _DEBUG_LOG_PATH})
print(f"[DEBUG] APP_STARTUP_BEGIN - debug_log_path={_DEBUG_LOG_PATH}", flush=True)
# #endregion

# #region agent log
_debug_log("A", "app.py:import_config", "IMPORTING_CONFIG", {})
# #endregion

# å°å…¥é…ç½®å’Œä¸»æ‡‰ç”¨
from simple_config import settings

# #region agent log
_debug_log("A", "app.py:config_loaded", "CONFIG_LOADED", {"port": settings.app_port, "flask_env": settings.flask_env, "line_token_set": bool(settings.line_channel_access_token), "notion_key_set": bool(settings.notion_api_key)})
# #endregion

# è¨­ç½®æ—¥èªŒ
import logging

# è¨­å®š Python logging ç´šåˆ¥ç‚º INFOï¼Œè®“ structlog å¯ä»¥è¼¸å‡º info ç´šåˆ¥æ—¥èªŒ
logging.basicConfig(
    format="%(message)s",
    level=logging.INFO,  # é€™æ˜¯é—œéµï¼æ²’æœ‰é€™è¡Œï¼Œé»˜èªæ˜¯ WARNING
)

structlog.configure(
    processors=[
        structlog.stdlib.filter_by_level,
        structlog.stdlib.add_logger_name,
        structlog.stdlib.add_log_level,
        structlog.stdlib.PositionalArgumentsFormatter(),
        structlog.processors.TimeStamper(fmt="ISO"),
        structlog.processors.StackInfoRenderer(),
        structlog.processors.format_exc_info,
        structlog.dev.ConsoleRenderer() if settings.debug else structlog.processors.JSONRenderer()
    ],
    wrapper_class=structlog.stdlib.BoundLogger,
    logger_factory=structlog.stdlib.LoggerFactory(),
    context_class=dict,
    cache_logger_on_first_use=True,
)

logger = structlog.get_logger()


# åˆå§‹åŒ– Redis å’Œæœå‹™
from src.namecard.infrastructure.redis_client import get_redis_client, close_redis_client
from src.namecard.core.services.user_service import user_service, create_user_service
from src.namecard.core.services.security import security_service, create_security_service

# åˆå§‹åŒ– Redis
redis_client = get_redis_client()

# å¦‚æœ Redis å¯ç”¨ï¼Œé‡æ–°å‰µå»ºæœå‹™å¯¦ä¾‹
if redis_client:
    # ä½¿ç”¨æ–°çš„ user_service å¯¦ä¾‹æ›¿æ›å…¨åŸŸå¯¦ä¾‹
    import src.namecard.core.services.user_service as user_service_module
    import src.namecard.core.services.security as security_module

    user_service_module.user_service = create_user_service(
        redis_client=redis_client,
        use_redis=True
    )

    security_module.security_service = create_security_service(
        redis_client=redis_client,
        use_redis=True
    )

    logger.info("Services initialized with Redis backend",
               services=["UserService", "SecurityService"])
else:
    logger.info("Services using in-memory backend (Redis not available)",
               services=["UserService", "SecurityService"])

# #region agent log
_debug_log("B", "app.py:before_main_import", "IMPORTING_LINE_BOT_MAIN", {})
# #endregion

# å°å…¥ä¸»æ‡‰ç”¨ï¼ˆåœ¨ Redis åˆå§‹åŒ–ä¹‹å¾Œï¼‰
try:
    from src.namecard.api.line_bot.main import app
    # #region agent log
    _debug_log("B", "app.py:main_imported", "LINE_BOT_MAIN_IMPORTED_OK", {})
    # #endregion
except Exception as _import_err:
    # #region agent log
    _debug_log("B", "app.py:main_import_failed", "LINE_BOT_MAIN_IMPORT_FAILED", {"error": str(_import_err), "error_type": type(_import_err).__name__})
    # #endregion
    raise

# ==================== å¤šç§Ÿæˆ¶ç®¡ç†å¾Œå°è¨­å®š ====================

# è¨­å®š Flask session secret key
admin_secret_key = os.environ.get("ADMIN_SECRET_KEY") or os.environ.get("SECRET_KEY", "dev-secret-key")
app.secret_key = admin_secret_key

# è¨»å†Šç®¡ç†å¾Œå° Blueprint
from src.namecard.api.admin import admin_bp
app.register_blueprint(admin_bp)

# ==================== SocketIO åˆå§‹åŒ– ====================
from src.namecard.api.admin.socketio_events import init_socketio, get_socketio
socketio = init_socketio(app)
logger.info("SocketIO initialized for real-time sync progress")

# #region agent log
_debug_log("C", "app.py:before_tenant_db", "INITIALIZING_TENANT_DB", {})
# #endregion

# åˆå§‹åŒ–ç§Ÿæˆ¶è³‡æ–™åº«
from src.namecard.infrastructure.storage.tenant_db import get_tenant_db
try:
    tenant_db = get_tenant_db()
    # #region agent log
    _debug_log("C", "app.py:tenant_db_ok", "TENANT_DB_INITIALIZED_OK", {"db_path": tenant_db.db_path})
    # #endregion
    logger.info("Tenant database initialized", db_path=tenant_db.db_path)
except Exception as e:
    # #region agent log
    _debug_log("C", "app.py:tenant_db_failed", "TENANT_DB_INIT_FAILED", {"error": str(e), "error_type": type(e).__name__})
    # #endregion
    logger.warning("Failed to initialize tenant database", error=str(e))

# åˆå§‹åŒ–ç®¡ç†å“¡èªè­‰ï¼ˆæœƒè‡ªå‹•å»ºç«‹åˆå§‹ç®¡ç†å“¡ï¼‰
try:
    from src.namecard.api.admin.auth import get_admin_auth
    admin_auth = get_admin_auth()
    logger.info("Admin authentication initialized")
except Exception as e:
    logger.warning("Failed to initialize admin auth", error=str(e))

logger.info("Multi-tenant admin panel enabled", admin_url="/admin")

# #region agent log
_debug_log("A", "app.py:admin_panel_enabled", "ADMIN_PANEL_ENABLED", {})

# è‡ªå‹•å‰µå»ºé è¨­ç§Ÿæˆ¶ï¼ˆå¾ç’°å¢ƒè®Šæ•¸ï¼‰
def init_default_tenant():
    """Auto-create default tenant from environment variables if all required vars are set"""
    from src.namecard.core.services.tenant_service import get_tenant_service
    from src.namecard.core.models.tenant import TenantCreateRequest

    # æª¢æŸ¥å¿…è¦ç’°å¢ƒè®Šæ•¸æ˜¯å¦éƒ½æœ‰è¨­å®š
    if not all([
        settings.line_channel_id,
        settings.line_channel_access_token,
        settings.line_channel_secret,
        settings.notion_api_key,
        settings.notion_database_id
    ]):
        logger.info("Skipping default tenant creation (incomplete env vars)")
        return

    try:
        tenant_service = get_tenant_service()

        # æª¢æŸ¥è©² channel_id çš„ç§Ÿæˆ¶æ˜¯å¦å·²å­˜åœ¨
        existing = tenant_service.get_tenant_by_channel_id(settings.line_channel_id)
        if existing:
            logger.info("Default tenant already exists", tenant_id=existing.id, name=existing.name)
            return

        # å‰µå»ºé è¨­ç§Ÿæˆ¶
        request = TenantCreateRequest(
            name="Default Tenant",
            slug="default",
            line_channel_id=settings.line_channel_id,
            line_channel_access_token=settings.line_channel_access_token,
            line_channel_secret=settings.line_channel_secret,
            notion_api_key=settings.notion_api_key,
            notion_database_id=settings.notion_database_id,
            google_api_key=settings.google_api_key if settings.google_api_key else None,
            use_shared_google_api=True,
        )
        tenant = tenant_service.create_tenant(request)
        logger.info("Default tenant auto-created from env vars", tenant_id=tenant.id)
    except Exception as e:
        logger.error("Failed to auto-create default tenant", error=str(e))

try:
    init_default_tenant()
    # #region agent log
    _debug_log("A", "app.py:default_tenant_init", "DEFAULT_TENANT_INIT_COMPLETED", {})
    # #endregion
except Exception as e:
    # #region agent log
    _debug_log("A", "app.py:default_tenant_init_failed", "DEFAULT_TENANT_INIT_FAILED", {"error": str(e), "error_type": type(e).__name__})
    # #endregion
    logger.warning("Default tenant initialization skipped", error=str(e))

# ===========================================================
# å…§åµŒ RQ Workerï¼ˆç•¶ Redis å¯ç”¨æ™‚è‡ªå‹•å•Ÿå‹•ï¼‰
# ===========================================================

_embedded_worker_started = False
_embedded_worker_lock_key = "embedded_rq_worker_lock"

def start_embedded_rq_worker():
    """
    åœ¨å¾Œå°ç·šç¨‹ä¸­å•Ÿå‹• RQ Worker
    
    ä½¿ç”¨ Redis åˆ†æ•£å¼é–ç¢ºä¿åªæœ‰ä¸€å€‹ Worker é‹è¡Œï¼ˆå³ä½¿æœ‰å¤šå€‹ Gunicorn workersï¼‰
    """
    global _embedded_worker_started
    if _embedded_worker_started:
        return
    
    import threading
    
    def run_worker():
        global _embedded_worker_started
        try:
            from rq import Worker, Queue
            from src.namecard.infrastructure.storage.image_upload_worker import RQ_QUEUE_NAME, get_rq_redis_client
            
            redis_client = get_rq_redis_client()
            if not redis_client:
                logger.warning("Embedded RQ Worker: Redis not available, will use sync upload")
                return
            
            # æ¸¬è©¦ Redis é€£æ¥
            redis_client.ping()
            
            # ä½¿ç”¨ Redis åˆ†æ•£å¼é–ç¢ºä¿åªæœ‰ä¸€å€‹ Worker
            # é–çš„ TTL ç‚º 60 ç§’ï¼ŒWorker æœƒæ¯ 30 ç§’æ›´æ–°ä¸€æ¬¡
            lock_acquired = redis_client.set(
                _embedded_worker_lock_key, 
                f"worker-{os.getpid()}", 
                nx=True,  # åªæœ‰ç•¶ key ä¸å­˜åœ¨æ™‚æ‰è¨­ç½®
                ex=60     # 60 ç§’éæœŸ
            )
            
            if not lock_acquired:
                existing_worker = redis_client.get(_embedded_worker_lock_key)
                logger.info("Embedded RQ Worker: Another worker already running", 
                           existing_worker=existing_worker.decode() if existing_worker else "unknown")
                return
            
            _embedded_worker_started = True
            logger.info("âœ… Embedded RQ Worker: Lock acquired, starting worker")
            
            # å‰µå»ºéšŠåˆ—å’Œ Worker
            queue = Queue(RQ_QUEUE_NAME, connection=redis_client)
            worker = Worker(
                [queue], 
                connection=redis_client, 
                name=f"embedded-worker-{os.getpid()}"
            )
            
            logger.warning("ğŸš€ EMBEDDED_RQ_WORKER_STARTED", queue=RQ_QUEUE_NAME, pid=os.getpid())
            
            # å®šæœŸæ›´æ–°é–ï¼ˆå¿ƒè·³ï¼‰
            def heartbeat():
                import time
                while _embedded_worker_started:
                    try:
                        redis_client.expire(_embedded_worker_lock_key, 60)
                    except:
                        pass
                    time.sleep(30)
            
            heartbeat_thread = threading.Thread(target=heartbeat, daemon=True)
            heartbeat_thread.start()
            
            # é–‹å§‹è™•ç†ä»»å‹™ï¼ˆæœƒé˜»å¡é€™å€‹ç·šç¨‹ï¼‰
            worker.work(with_scheduler=False, logging_level='WARNING')
            
        except ImportError as e:
            logger.warning("Embedded RQ Worker: RQ not installed, will use sync upload", error=str(e))
        except Exception as e:
            logger.error("Embedded RQ Worker failed, will use sync upload", error=str(e), error_type=type(e).__name__)
        finally:
            _embedded_worker_started = False
            # é‡‹æ”¾é–ï¼ˆç¢ºä¿ redis_client å­˜åœ¨ï¼‰
            try:
                if 'redis_client' in dir() and redis_client:
                    redis_client.delete(_embedded_worker_lock_key)
            except:
                pass
    
    # åœ¨å¾Œå°ç·šç¨‹ä¸­é‹è¡Œ
    worker_thread = threading.Thread(target=run_worker, daemon=True, name="EmbeddedRQWorker")
    worker_thread.start()
    logger.info("Embedded RQ Worker thread launched")

# ä½¿ç”¨ç’°å¢ƒè®Šæ•¸æ§åˆ¶æ˜¯å¦å•Ÿå‹•å…§åµŒ Worker
if os.environ.get("ENABLE_EMBEDDED_RQ_WORKER", "true").lower() in ("true", "1", "yes"):
    try:
        start_embedded_rq_worker()
        _debug_log("A", "app.py:embedded_worker", "EMBEDDED_RQ_WORKER_LAUNCHED", {})
    except Exception as e:
        logger.warning("Failed to launch embedded RQ worker", error=str(e))
        _debug_log("A", "app.py:embedded_worker_failed", "EMBEDDED_RQ_WORKER_LAUNCH_FAILED", {"error": str(e)})
else:
    logger.info("Embedded RQ Worker disabled by ENABLE_EMBEDDED_RQ_WORKER=false")

# #region agent log
_debug_log("A", "app.py:startup_complete", "APP_STARTUP_COMPLETE", {"ready_for_gunicorn": True})
print("[DEBUG] APP_STARTUP_COMPLETE - ready_for_gunicorn=True", flush=True)
# #endregion

# ===========================================================

def main():
    """ä¸»å‡½æ•¸"""
    logger.info("Starting LINE Bot Namecard System",
                version="3.0.0",
                port=settings.app_port,
                environment=settings.flask_env,
                multi_tenant=True)
    
    try:
        # ä½¿ç”¨ SocketIO å•Ÿå‹•ï¼ˆæ”¯æ´ WebSocketï¼‰
        from src.namecard.api.admin.socketio_events import get_socketio
        sio = get_socketio()
        if sio:
            sio.run(
                app,
                host=settings.app_host,
                port=settings.app_port,
                debug=settings.debug,
                allow_unsafe_werkzeug=True,
            )
        else:
            # Fallback to regular Flask
            app.run(
                host=settings.app_host,
                port=settings.app_port,
                debug=settings.debug,
                threaded=True
            )
    except KeyboardInterrupt:
        logger.info("Application stopped by user")
    except Exception as e:
        logger.error("Application startup failed", error=str(e))
        sys.exit(1)
    finally:
        # æ¸…ç† Redis é€£æ¥
        close_redis_client()
        logger.info("Application shutdown complete")

# å°å‡º Flask æ‡‰ç”¨å¯¦ä¾‹ä¾› gunicorn ä½¿ç”¨
application = app

if __name__ == "__main__":
    main()