#!/usr/bin/env python3
"""
Sentry ç›£æ§åŠŸèƒ½æ¸¬è©¦è…³æœ¬
æ¸¬è©¦æ‰€æœ‰ç›£æ§äº‹ä»¶å’Œè­¦å ±æ©Ÿåˆ¶
"""

import sys
import os
import time
from datetime import datetime

# æ·»åŠ å°ˆæ¡ˆæ ¹ç›®éŒ„åˆ°è·¯å¾‘
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from src.namecard.core.services.monitoring import (
    monitoring_service, MonitoringEvent, EventCategory, MonitoringLevel,
    monitor_performance, monitor_ai_processing, PerformanceMetric
)


def test_basic_monitoring():
    """æ¸¬è©¦åŸºæœ¬ç›£æ§åŠŸèƒ½"""
    print("ğŸ§ª æ¸¬è©¦åŸºæœ¬ç›£æ§åŠŸèƒ½...")
    
    # æ¸¬è©¦ä¸åŒç´šåˆ¥çš„äº‹ä»¶
    test_events = [
        (MonitoringLevel.INFO, "System startup completed"),
        (MonitoringLevel.WARNING, "High memory usage detected"),
        (MonitoringLevel.ERROR, "Database connection failed"),
        (MonitoringLevel.CRITICAL, "Service completely unavailable")
    ]
    
    for level, message in test_events:
        event = MonitoringEvent(
            category=EventCategory.SYSTEM_PERFORMANCE,
            level=level,
            message=message,
            user_id="test_user_123",
            extra_data={"test": True, "timestamp": datetime.now().isoformat()},
            tags={"test_type": "basic_monitoring", "severity": level.value}
        )
        
        monitoring_service.capture_event(event)
        print(f"   âœ… {level.value.upper()}: {message}")
        time.sleep(0.5)


def test_performance_monitoring():
    """æ¸¬è©¦æ•ˆèƒ½ç›£æ§"""
    print("\nğŸš€ æ¸¬è©¦æ•ˆèƒ½ç›£æ§...")
    
    # æ¨¡æ“¬ä¸åŒæ“ä½œçš„æ•ˆèƒ½æŒ‡æ¨™
    operations = [
        ("ai_processing", 2.5, True),
        ("notion_save", 1.2, True),
        ("image_upload", 0.8, True),
        ("slow_operation", 8.0, False),  # æ…¢æ“ä½œ
        ("failed_operation", 0.1, False)  # å¤±æ•—æ“ä½œ
    ]
    
    for operation, duration, success in operations:
        metric = PerformanceMetric(
            operation=operation,
            duration=duration,
            success=success,
            user_id="test_user_456",
            metadata={
                "test": True,
                "simulated": True,
                "operation_details": f"Test {operation}"
            }
        )
        
        monitoring_service.track_performance(metric)
        status = "âœ… SUCCESS" if success else "âŒ FAILED"
        print(f"   {status} {operation}: {duration}s")
        time.sleep(0.3)


def test_ai_processing_monitoring():
    """æ¸¬è©¦ AI è™•ç†ç›£æ§"""
    print("\nğŸ¤– æ¸¬è©¦ AI è™•ç†ç›£æ§...")
    
    @monitor_ai_processing
    def mock_ai_processing(image_size: int, user_id: str):
        """æ¨¡æ“¬ AI è™•ç†"""
        if image_size > 5000000:  # 5MB
            raise Exception("Image too large for processing")
        
        time.sleep(1)  # æ¨¡æ“¬è™•ç†æ™‚é–“
        return {"cards": 2, "confidence": 0.95}
    
    # æ¸¬è©¦æˆåŠŸæ¡ˆä¾‹
    try:
        result = mock_ai_processing(1000000, "test_user_ai_1")
        print(f"   âœ… AI Processing Success: {result}")
    except Exception as e:
        print(f"   âŒ AI Processing Failed: {e}")
    
    # æ¸¬è©¦å¤±æ•—æ¡ˆä¾‹
    try:
        result = mock_ai_processing(6000000, "test_user_ai_2")
        print(f"   âœ… AI Processing Success: {result}")
    except Exception as e:
        print(f"   âŒ AI Processing Failed: {e}")


def test_error_categories():
    """æ¸¬è©¦ä¸åŒé¡åˆ¥çš„éŒ¯èª¤ç›£æ§"""
    print("\nğŸ” æ¸¬è©¦éŒ¯èª¤åˆ†é¡ç›£æ§...")
    
    error_scenarios = [
        {
            "category": EventCategory.AI_PROCESSING,
            "level": MonitoringLevel.ERROR,
            "message": "Gemini API quota exceeded",
            "extra_data": {"api_calls_today": 1000, "quota_limit": 1000}
        },
        {
            "category": EventCategory.DATA_STORAGE,
            "level": MonitoringLevel.CRITICAL,
            "message": "Notion database corruption detected",
            "extra_data": {"affected_records": 150, "last_backup": "2024-01-15"}
        },
        {
            "category": EventCategory.LINE_BOT,
            "level": MonitoringLevel.WARNING,
            "message": "High webhook response time",
            "extra_data": {"avg_response_time": 4.5, "threshold": 3.0}
        },
        {
            "category": EventCategory.SECURITY,
            "level": MonitoringLevel.CRITICAL,
            "message": "Multiple failed authentication attempts",
            "extra_data": {"failed_attempts": 10, "source_ip": "192.168.1.100"}
        },
        {
            "category": EventCategory.USER_BEHAVIOR,
            "level": MonitoringLevel.INFO,
            "message": "User engagement spike detected",
            "extra_data": {"active_users": 500, "normal_range": "50-100"}
        }
    ]
    
    for scenario in error_scenarios:
        event = MonitoringEvent(
            category=scenario["category"],
            level=scenario["level"],
            message=scenario["message"],
            user_id="test_user_category",
            extra_data=scenario["extra_data"],
            tags={"test_category": scenario["category"].value}
        )
        
        monitoring_service.capture_event(event)
        print(f"   ğŸ“Š {scenario['category'].value}: {scenario['message']}")
        time.sleep(0.4)


def test_user_context():
    """æ¸¬è©¦ç”¨æˆ¶ä¸Šä¸‹æ–‡è¨­å®š"""
    print("\nğŸ‘¤ æ¸¬è©¦ç”¨æˆ¶ä¸Šä¸‹æ–‡...")
    
    # è¨­å®šç”¨æˆ¶ä¸Šä¸‹æ–‡
    monitoring_service.set_user_context("test_user_context", {
        "email": "test@example.com",
        "subscription": "premium",
        "join_date": "2024-01-01"
    })
    
    # æ·»åŠ éºµåŒ…å±‘
    monitoring_service.add_breadcrumb("User started card processing", "user_action", {
        "card_count": 3,
        "batch_mode": True
    })
    
    monitoring_service.add_breadcrumb("AI analysis completed", "ai_processing", {
        "processing_time": 2.1,
        "confidence": 0.92
    })
    
    # è§¸ç™¼äº‹ä»¶
    event = MonitoringEvent(
        category=EventCategory.USER_BEHAVIOR,
        level=MonitoringLevel.INFO,
        message="User completed card processing session",
        user_id="test_user_context",
        extra_data={
            "cards_processed": 3,
            "success_rate": 1.0,
            "session_duration": 45.2
        }
    )
    
    monitoring_service.capture_event(event)
    print("   âœ… User context and breadcrumbs set")


def test_performance_summary():
    """æ¸¬è©¦æ•ˆèƒ½æ‘˜è¦"""
    print("\nğŸ“ˆ æ¸¬è©¦æ•ˆèƒ½æ‘˜è¦...")
    
    summary = monitoring_service.get_performance_summary()
    
    print("   ğŸ“Š Performance Summary:")
    if isinstance(summary, dict) and "total_operations" in summary:
        print(f"      â€¢ Total Operations: {summary.get('total_operations', 0)}")
        print(f"      â€¢ Success Rate: {summary.get('success_rate', 0):.1f}%")
        print(f"      â€¢ Average Duration: {summary.get('avg_duration', 0):.2f}s")
        print(f"      â€¢ Max Duration: {summary.get('max_duration', 0):.2f}s")
        
        if "operation_breakdown" in summary:
            print("      â€¢ Operation Breakdown:")
            for op, stats in summary["operation_breakdown"].items():
                print(f"        - {op}: {stats.get('count', 0)} ops, "
                      f"{stats.get('success_rate', 0):.1f}% success")
    else:
        print(f"      â€¢ Summary: {summary}")


def test_exception_handling():
    """æ¸¬è©¦ç•°å¸¸æ•ç²"""
    print("\nğŸš¨ æ¸¬è©¦ç•°å¸¸æ•ç²...")
    
    try:
        # æ•…æ„è§¸ç™¼ç•°å¸¸
        raise ValueError("This is a test exception for monitoring")
    except Exception as e:
        monitoring_service.capture_exception_with_context(
            e,
            EventCategory.SYSTEM_PERFORMANCE,
            user_id="test_user_exception",
            extra_context={
                "test_type": "exception_handling",
                "expected": True,
                "function": "test_exception_handling"
            }
        )
        print("   âœ… Exception captured and sent to monitoring")


def main():
    """ä¸»æ¸¬è©¦å‡½æ•¸"""
    print("ğŸ¯ é–‹å§‹ Sentry ç›£æ§åŠŸèƒ½æ¸¬è©¦")
    print(f"âš™ï¸  ç›£æ§æœå‹™ç‹€æ…‹: {'å•Ÿç”¨' if monitoring_service.is_enabled else 'åœç”¨'}")
    print("=" * 60)
    
    # é‹è¡Œæ‰€æœ‰æ¸¬è©¦
    test_basic_monitoring()
    test_performance_monitoring()
    test_ai_processing_monitoring()
    test_error_categories()
    test_user_context()
    test_exception_handling()
    test_performance_summary()
    
    print("\n" + "=" * 60)
    print("ğŸ‰ æ‰€æœ‰ç›£æ§æ¸¬è©¦å®Œæˆï¼")
    
    if monitoring_service.is_enabled:
        print("ğŸ“§ è«‹æª¢æŸ¥ä½ çš„ Sentry Dashboard æŸ¥çœ‹æ‰€æœ‰æ¸¬è©¦äº‹ä»¶")
        print("ğŸ”— Dashboard: https://sentry.io")
    else:
        print("âš ï¸  Sentry SDK æœªå•Ÿç”¨ï¼Œäº‹ä»¶åƒ…è¨˜éŒ„åˆ°æœ¬åœ°æ—¥èªŒ")
    
    print("\nğŸ’¡ æç¤ºï¼š")
    print("   - åœ¨ç”Ÿç”¢ç’°å¢ƒä¸­ï¼Œäº‹ä»¶æœƒè‡ªå‹•ç™¼é€åˆ° Sentry")
    print("   - å¯ä»¥è¨­å®šè­¦å ±è¦å‰‡ä¾†ç›£æ§é—œéµæŒ‡æ¨™")
    print("   - ä½¿ç”¨ Dashboard åˆ†æéŒ¯èª¤è¶¨å‹¢å’Œæ•ˆèƒ½ç“¶é ¸")


if __name__ == "__main__":
    main()